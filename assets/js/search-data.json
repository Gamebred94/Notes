{
  
    
        "post0": {
            "title": "An introduction to Reinforcement Learning",
            "content": "%matplotlib inline import PIL import gym import matplotlib as mpl import matplotlib.pyplot as plt mpl.rc(&#39;axes&#39;, labelsize=14) mpl.rc(&#39;xtick&#39;, labelsize=12) mpl.rc(&#39;ytick&#39;, labelsize=12) # To get smooth animations import matplotlib.animation as animation import matplotlib.pyplot as plt mpl.rc(&#39;animation&#39;, html=&#39;jshtml&#39;) # Imports specifically so we can render outputs in Jupyter. #from JSAnimation.IPython_display import display_animation from matplotlib import animation from IPython.display import display import tensorflow as tf import pandas as pd from tensorflow import keras . . What is RL? . In a nutshell, RL is the study of agents and how they learn by trial and error | It formalizes the idea that rewarding or punishing an agent for its behavior makes it more likely to repeat or forego that behavior in the future | . This is quite a broad setting, which can apply to a wide variety of tasks. . . The agent can be the program controlling a robot. In this case, the environment is the real world, the agent observes the environment through a set of sensors such as cameras and touch sensors, and its actions consist of sending signals to activate motors | The agent can be the program controlling Ms. Pac-Man. In this case, the environment is a simulation of the Atari game | The agent can be the program playing a board game such as Go | The agent does not have to control a physically (or virtually) moving thing. A smart thermostat, getting positive rewards whenever it is close to the target temperature and saves energy, and negative rewards when humans need to tweak the temperature | The agent can observe stock market prices and decide how much to buy or sell every second. Rewards are obviously the monetary gains and losses | RL framework . . Key Concepts and Terminology: . The main characters of RL are the agent and the environment: . The agent is an entity which is of interest to us | The environment is the world that the agent lives in and interacts with. At every step of interaction, the agent sees a (possibly partial) observation of the state of the environment, and then decides on an action to take | The environment changes when the agent acts on it, but may also change on its own | . | Moreover: . The agent perceives a reward signal from the environment, a number that tells it how good or bad the current world state is | The goal of the agent is to maximize its cumulative reward, called return. Reinforcement learning methods are ways that the agent can learn behaviors to achieve its goal | . | To talk more specifically what RL does, we need to introduce additional terminology. We need to talk about states and observations, action spaces, policies, return, and value functions. . States and Observations . A state &#39;s&#39; is a complete description of the state of the world. There is no information about the world which is hidden from the state. | An observation o is a partial description of a state, which may omit information. A lot of the times, observations and state are used interchangeably . | In deep RL, we almost always represent states and observations by a real-valued vector, matrix, or higher-order tensor For instance, a visual observation could be represented by the RGB matrix of its pixel values; the state of a robot might be represented by its joint angles and velocities . | . Action Spaces . Different environments allow different kinds of actions | The set of all valid actions in a given environment is often called the action space. Some environments, like Atari and Go, have discrete action spaces, where only a finite number of moves are available to the agent Other environments, like where the agent controls a robot in a physical world, have continuous action spaces | . Policies . The algorithm a software agent uses to determine its actions is called its policy. It can be deterministic or stochastic denoted by $ Pi$ | Because the policy is essentially the agent’s brain, it’s not uncommon to substitute the word “policy” for “agent”, eg saying “The policy is trying to maximize reward.” | In deep RL, we deal with parameterized policies i.e policies whose outputs are computable functions that depend on a set of parameters (eg the weights and biases of a neural network) which we can adjust to change the behavior via some optimization algorithm | . .",
            "url": "https://gamebred94.github.io/reinforcement-learning/2021/10/06/test2.html",
            "relUrl": "/2021/10/06/test2.html",
            "date": " • Oct 6, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "An Example Markdown Post",
            "content": "Example Markdown Post . Basic setup . Jekyll requires blog post files to be named according to the following format: . YEAR-MONTH-DAY-filename.md . Where YEAR is a four-digit number, MONTH and DAY are both two-digit numbers, and filename is whatever file name you choose, to remind yourself what this post is about. .md is the file extension for markdown files. . The first line of the file should start with a single hash character, then a space, then your title. This is how you create a “level 1 heading” in markdown. Then you can create level 2, 3, etc headings as you wish but repeating the hash character, such as you see in the line ## File names above. . Basic formatting . You can use italics, bold, code font text, and create links. Here’s a footnote 1. Here’s a horizontal rule: . . Lists . Here’s a list: . item 1 | item 2 | . And a numbered list: . item 1 | item 2 | Boxes and stuff . This is a quotation . . You can include alert boxes …and… . . You can include info boxes Images . . Code . You can format text and code per usual . General preformatted text: . # Do a thing do_thing() . Python code and output: . # Prints &#39;2&#39; print(1+1) . 2 . Formatting text as shell commands: . echo &quot;hello world&quot; ./some_script.sh --option &quot;value&quot; wget https://example.com/cat_photo1.png . Formatting text as YAML: . key: value - another_key: &quot;another value&quot; . Tables . Column 1 Column 2 . A thing | Another thing | . Tweetcards . Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 Footnotes . This is the footnote. &#8617; . |",
            "url": "https://gamebred94.github.io/reinforcement-learning/markdown/2020/01/14/test-markdown-post.html",
            "relUrl": "/markdown/2020/01/14/test-markdown-post.html",
            "date": " • Jan 14, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://gamebred94.github.io/reinforcement-learning/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://gamebred94.github.io/reinforcement-learning/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}