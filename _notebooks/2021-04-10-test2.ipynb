{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An introduction to Reinforcement Learning\n",
    "> Demo and Discussion of RL & OpenAI gym "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import PIL\n",
    "import gym\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# To get smooth animations\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('animation', html='jshtml')\n",
    "# Imports specifically so we can render outputs in Jupyter.\n",
    "#from JSAnimation.IPython_display import display_animation\n",
    "from matplotlib import animation\n",
    "from IPython.display import display\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is RL?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- One possible learning algorithm could be to try out many different values for these parameters, and pick the\n",
    "combination that performs best (see above Figure).  \n",
    "This is an example of ***policy search using a brute force approach***. When the policy space is too\n",
    "large (which is generally the case), finding a good set of parameters  \n",
    "this way is like searching for a needle in a gigantic haystack.\n",
    "- Another way to explore the policy space is to use genetic algorithms. For example, you could randomly create a first generation of 100 policies and try them out,  \n",
    "then “kill” the 80 worst policies and make the 20 survivors produce 4 offspring each.  \n",
    "An offspring is a copy of its parent plus some random variation. The surviving policies plus their offspring together constitute the second generation.  \n",
    "we can continue to iterate through generations this way until we find a good policy.\n",
    "- Yet another approach is to use optimization techniques, by evaluating the\n",
    "gradients of the rewards with regard to the policy parameters,  \n",
    "then tweaking these parameters by following the gradients toward higher rewards.  \n",
    "This approach, is called **policy gradients (PG)** .  \n",
    "Going back to the vacuum cleaner robot, you could slightly increase p and evaluate whether doing so increases the amount of dust picked up by the robot in 30 minutes;  \n",
    "if it does, then increase p some more, or else reduce p."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
