{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \"An introduction to Reinforcement Learning\"\n",
    "> \"Demo and Discussion of RL & OpenAI gym\"\n",
    "\n",
    "- toc:true- branch: master\n",
    "- badges: true\n",
    "- comments: true\n",
    "- author: Ashish Gusain\n",
    "- categories: [Reinforcement learning, Python, fastpages, jupyter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import PIL\n",
    "import gym\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# To get smooth animations\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('animation', html='jshtml')\n",
    "# Imports specifically so we can render outputs in Jupyter.\n",
    "#from JSAnimation.IPython_display import display_animation\n",
    "from matplotlib import animation\n",
    "from IPython.display import display\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is RL?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](images/RL_applications.JPG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In a nutshell, RL is the study of agents and how they learn by trial and error. \n",
    "- It formalizes the idea that rewarding or punishing an agent for its behavior makes it more likely to repeat or forego that behavior in the future.\n",
    "\n",
    "This is quite a broad setting, which can apply to a wide variety of tasks.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The agent can be the program controlling a robot. In this case, the environment is the real world, the agent observes the environment through a  \n",
    "set of sensors such as cameras and touch sensors, and its actions consist of sending signals to activate motors.  \n",
    "1. The agent can be the program controlling Ms. Pac-Man. In this case, the environment is a simulation of the Atari game.\n",
    "\n",
    "1. The agent can be the program playing a board game such as Go.\n",
    "\n",
    "1. The agent does not have to control a physically (or virtually) moving thing. A smart thermostat, getting positive rewards whenever  \n",
    "   it is close to the target temperature and saves energy, and negative rewards when humans need to tweak the temperature.\n",
    "\n",
    "1. The agent can observe stock market prices and decide how much to buy\n",
    "or sell every second. Rewards are obviously the monetary gains and\n",
    "losses."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
